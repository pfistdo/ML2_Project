{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Breed Classifier\n",
    "This is a model used to classify different dog breeds. The dataset used to train the model contains 70 different dog breeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start working with our data we need to extract the data.zip file. This is required to run the project on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data.zip'\n",
    "\n",
    "try:\n",
    "  f = open(file_name)\n",
    "  with ZipFile(file_name, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    print('Complete')\n",
    "except FileNotFoundError:\n",
    "  print('File \"data.zip\" is missing. Please create the ZIP file first')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the zip file is extracted we can read in our dataset. We have 70 classes split in train, validation and test directories. We will be using the train directory to train our model and the test directory to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train'\n",
    "VAL_DIR = 'data/test'\n",
    "                \n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# required for data augmentation\n",
    "data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    # preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    # shear_range=0.2,\n",
    "    # zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_dataset = data_generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_dataset = data_generator.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to fetch the class labels once the model is completed we convert the classlabels to a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_labels = train_dataset.class_indices\n",
    "classes_labels = dict((v,k) for k,v in classes_labels.items())\n",
    "classes_labels = [classes_labels[i] for i in range(len(classes_labels))]\n",
    "print(classes_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned our dataset contains dog breeds of 70 different classes. This can be tested with the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset contains a total of {len(train_dataset.class_indices)} classes.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our images are RGB images and have the dimensions of 224x224 which is very common for image classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_dataset:\n",
    "    print(f\"Image batch shape: {image_batch.shape}\")\n",
    "    print(f\"Label batch shape: {label_batch.shape}\")\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see a couple examples of the different classes. The images are all of the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image_batch[i].astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    label = label_batch[i].argmax()\n",
    "    plt.title(list(train_dataset.class_indices.keys())[label])\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can start building our model. We will use mobilenetv2 as our base model and add a classification layer on top of it. Because we want to use the existing weights from the basemodel we want to freeze these weights so our model is only training on our new layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processing = tf.keras.Sequential([tf.keras.layers.Input((224,224,3)),\n",
    "                             tf.keras.layers.Lambda(tf.keras.applications.mobilenet_v2.preprocess_input)])\n",
    "\n",
    "mobilenet_v2 = tf.keras.applications.MobileNetV2(input_shape = (224,224,3), \n",
    "                                                 include_top = False)\n",
    "mobilenet_v2.trainable = False  # Freeze MobileNetV2 layers\n",
    "\n",
    "classifier = tf.keras.Sequential([tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                             tf.keras.layers.Dropout(0.5),\n",
    "                             tf.keras.layers.Dense(70, activation = 'softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))])\n",
    "\n",
    "dog_classifier_mobile = tf.keras.Sequential([pre_processing, \n",
    "                                             mobilenet_v2,\n",
    "                                             classifier])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is created we can define an optimizer and compile our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "dog_classifier_mobile.compile(optimizer = opt, \n",
    "                              loss = 'categorical_crossentropy', \n",
    "                              metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to build it and create a summary. We can see that our model has a preprocessing layer, the whole mobilenetv2 with all it's layers and our own sequential classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_classifier_mobile.build(((None, 224, 224, 3)))\n",
    "dog_classifier_mobile.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce overfitting we define an early stopping callback. Once this is done we can train our model. To reduce computational time we will train our model with 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode='min', restore_best_weights=False)\n",
    "\n",
    "history = dog_classifier_mobile.fit(train_dataset, \n",
    "                                    validation_data = val_dataset, \n",
    "                                    epochs = epochs, \n",
    "                                    callbacks=[early_stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training of the model a total of 10 of epochs were performed to optimize the model's performance. The training started with an initial loss of 5.0839 and an accuracy of 0.1172. After 10 epochs, the final loss decreased to 1.3228, while the accuracy increased to 0.8710. The validation loss further decreased to 1.0883, and the validation accuracy reached 0.9343. These improvements indicate that the model effectively learned to classify the images in the dataset. During the training, there was a decrease in both loss and validation loss. This means that the model was learning and making more accurate predictions as the training progressed and did not overfit.\n",
    "\n",
    "The validation accuracy of 0.9343 in the last epoch shows that the model was able to handle unseen data well. This means the model can effectively classify new images with a high degree of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `save()` function we can save the model. To better organize the project we save the output in the *models* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_classifier_mobile.save('models/dog_classifier_mobile.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions we load the model again using the `load_model()` function. Once the model is loaded we can try and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('models/dog_classifier_mobile.h5')\n",
    "dog_path = 'data/test/Afghan/01.jpg'\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    dog_path, target_size=IMG_SIZE\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(f\"This dog is a {classes_labels[np.argmax(score)]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
